{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_talos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12MywzemOco9GPDP_QPHTJZR7YOsKTjua",
      "authorship_tag": "ABX9TyOeuGTwsJRhZ5K55mazIdh0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m10923039/-/blob/main/CNN_talos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFAkjZ9jLjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67663a4-908e-41e1-f414-bd3c2d25743d"
      },
      "source": [
        "!pip install talos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting talos\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/90/2455415b2a2170ad649b66d79ea74ff1af546c012836a2b621323a5fabfd/talos-1.0-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
            "\u001b[?25hCollecting statsmodels>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/69/8eef30a6237c54f3c0b524140e2975f4b1eea3489b45eb3339574fc8acee/statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from talos) (0.0)\n",
            "Collecting chances\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/d8/d61112d7476dc3074b855f1edd8556cde9b49b7106853f0b060109dd4c82/chances-0.1.9.tar.gz\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from talos) (4.41.1)\n",
            "Collecting astetik\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/c1/b40ed42915c66d54728a6059de0d35088b329a677f01e9c6f50a71b5b361/astetik-1.11.1-py3-none-any.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 27.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from talos) (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from talos) (2.23.0)\n",
            "Collecting wrangle\n",
            "  Downloading https://files.pythonhosted.org/packages/85/35/bc729e377417613f2d062a890faea5d649ef1a554df21499e9c3a4a5501a/wrangle-0.6.7.tar.gz\n",
            "Collecting kerasplotlib\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b7/31663d3b5ea9afd8c2c6ffa06d3c4e118ef363e12dc75b7c49fb6a2d22aa/kerasplotlib-0.1.6.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from talos) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from talos) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.0->talos) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.0->talos) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->talos) (0.22.2.post1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from astetik->talos) (5.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from astetik->talos) (0.11.1)\n",
            "Collecting geonamescache\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/ba/b7939087621bfeb24c0f52c4b879865a9f902cda72efd119f4275400e692/geonamescache-1.2.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.3.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.0.0->talos) (1.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->talos) (2.10)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from wrangle->talos) (2.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->talos) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->talos) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->talos) (1.0.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (54.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->astetik->talos) (0.8.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->astetik->talos) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.3.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->wrangle->talos) (3.13)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->astetik->talos) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython->astetik->talos) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->astetik->talos) (0.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->astetik->talos) (2.4.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->talos) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.0.0->talos) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.0.0->talos) (3.4.1)\n",
            "Building wheels for collected packages: chances, wrangle, kerasplotlib\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chances: filename=chances-0.1.9-cp37-none-any.whl size=41610 sha256=e294a2d2b2d347daf556170d38a6de5776185a8a38228402d24dd25ebd134e13\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/33/46/c871b94249bd57d17797d049b3dff8e3a09c315afb67eb14c6\n",
            "  Building wheel for wrangle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrangle: filename=wrangle-0.6.7-cp37-none-any.whl size=49894 sha256=215d87f5fc5bdcdeec9a3bd664d2d0e92f4c2d642642e13e7efde7212955b938\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/1b/50/d0403ce6ef269e364894da7b50db68db14c4ac62c577561e2d\n",
            "  Building wheel for kerasplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kerasplotlib: filename=kerasplotlib-0.1.6-cp37-none-any.whl size=3603 sha256=4f7478ef588db0ffa00b96797b7ae864f987891e57b854f33b3249848d155f77\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/d3/8c/9503a22b0a38e8b21c70ad834e4606d209193443e5c709305d\n",
            "Successfully built chances wrangle kerasplotlib\n",
            "\u001b[31mERROR: wrangle 0.6.7 has requirement scipy==1.2, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: statsmodels, chances, wrangle, geonamescache, astetik, kerasplotlib, talos\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed astetik-1.11.1 chances-0.1.9 geonamescache-1.2.0 kerasplotlib-0.1.6 statsmodels-0.12.2 talos-1.0 wrangle-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jkNJBKyfNgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9d4285-9eac-46d9-ed3a-b61537f71229"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout,Conv2D,Activation,BatchNormalization,MaxPooling2D\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# import talos\n",
        "# from talos.utils.gpu_utils import multi_gpu\n",
        "\n",
        "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# 讀取 cifar10 檔案\n",
        "((train_feature, train_label), (test_feature, test_label)) = cifar10.load_data()\n",
        "\n",
        "# MinMax 將 像素縮放到0~1\n",
        "train_feature_vector = train_feature / 255\n",
        "\n",
        "# onehot 編碼\n",
        "train_label_onehot = np_utils.to_categorical(train_label)\n",
        "\n",
        "# 切分 validation_data ，可以不做\n",
        "(x_train,x_val,y_train,y_val) =train_test_split(train_feature_vector, train_label_onehot, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# 測試 資料的預處理\n",
        "test_feature_vector = test_feature / 255\n",
        "test_label_onehot = np_utils.to_categorical(test_label)\n",
        "\n",
        "# 各個變數的 shape\n",
        "print( 'train feature datas =', train_feature.shape )\n",
        "print( 'test feature datas =', test_feature.shape )\n",
        "print( 'x_train =', x_train.shape )\n",
        "print( 'y_train =', y_train.shape )\n",
        "print( 'x_val =', x_val.shape )\n",
        "print( 'y_val =', y_val.shape )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "train feature datas = (50000, 32, 32, 3)\n",
            "test feature datas = (10000, 32, 32, 3)\n",
            "x_train = (40000, 32, 32, 3)\n",
            "y_train = (40000, 10)\n",
            "x_val = (10000, 32, 32, 3)\n",
            "y_val = (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv9eDyC-u5tE"
      },
      "source": [
        "# 測試pre_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dVsVM-6kp9t"
      },
      "source": [
        "# 選取 pre_model 的層數\n",
        "test_model = VGG16(include_top=False, weights='imagenet', input_tensor=None,\n",
        "      input_shape = (x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR4MJtqth7yt"
      },
      "source": [
        "test_model.save('VGG16.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggQwzIuVxL1l"
      },
      "source": [
        "test_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5cneN_smTdM",
        "outputId": "29ca0fc4-cba0-41bf-cce7-dd8e8584dc4e"
      },
      "source": [
        "test_model = Model(inputs=test_model.input, outputs=test_model.get_layer('block3_conv2').output)\n",
        "#  Model(inputs=net.input, outputs=output_layer)\n",
        "len(test_model.layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZQPOFtftsX"
      },
      "source": [
        "# **TPU準備**\n",
        "載入 TPU 程式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9DBe5QpfV_1"
      },
      "source": [
        "import os\n",
        "tf.keras.backend.clear_session()\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver('grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnmVFi42OWkb"
      },
      "source": [
        "# 模型 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq8N5dxzfzzA"
      },
      "source": [
        "def minimal(x1,y1,x2,y2):\n",
        "                              # l1 = tf.keras.regularizers.l1(0.01)\n",
        "                              # p = {'activation':['relu', 'elu'],\n",
        "                              #       'optimizer': ['Nadam', 'Adam'],\n",
        "                              #       'losses': ['categorical_crossentropy'],\n",
        "                              #       'batch_size': [64,128,256],\n",
        "                              #       'epochs': [60],\n",
        "                              #       'node_1' : [64,256,1024],\n",
        "                              #       'node_2' : [64,128,256],\n",
        "                              #       'regularizers' :[l2,l1]\n",
        "                              #     }\n",
        "# p 設定要搜索的參數 字典\n",
        "# \n",
        "# \n",
        "  l2 = tf.keras.regularizers.l2(0.01)\n",
        "  p = {'activation':['relu'],\n",
        "      'optimizer': ['Adam'],\n",
        "      'losses': ['categorical_crossentropy'],\n",
        "      'batch_size': [1500,3000],\n",
        "      'epochs': [60],\n",
        "      'node_1' : [256,384],\n",
        "      'node_2' : [256,384],\n",
        "      'regularizers' :[l2]\n",
        "    }\n",
        "      \n",
        "  def create_model(params):\n",
        "      net = VGG16(include_top=False, weights='imagenet', input_tensor=None,\n",
        "              input_shape = (x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
        "              )\n",
        "      \n",
        "      # 透過layer_name 節取 model的某一層\n",
        "      layer_name='block3_conv3'\n",
        "\n",
        "      # 設定取到該層的都使用預設參數，不訓練參數\n",
        "      layer_index=net.layers.index(net.get_layer(layer_name))\n",
        "      \n",
        "      # 建立模型\n",
        "      base_model = net.get_layer(layer_name).output\n",
        "      base_model = tf.keras.layers.Conv2D(128, (1, 1), padding='valid')(base_model)\n",
        "      base_model = tf.keras.layers.MaxPooling2D( pool_size = (3, 3) )(base_model)\n",
        "      \n",
        "      # 攤平 feature map \n",
        "      base_model = Flatten()(base_model)\n",
        "      \n",
        "\n",
        "      base_model = Dropout(0.3)(base_model)\n",
        "      base_model = tf.keras.layers.BatchNormalization()(base_model)\n",
        "      base_model = Dense(units = params['node_1'], kernel_initializer = tf.keras.initializers.GlorotNormal()\n",
        "                 ,kernel_regularizer= params['regularizers'] , activation= params['activation'])(base_model)\n",
        "\n",
        "\n",
        "      base_model = Dense(units = params['node_2'], kernel_initializer = tf.keras.initializers.GlorotNormal()\n",
        "                 ,kernel_regularizer = params['regularizers'] , activation= params['activation'])(base_model)\n",
        "\n",
        "      base_model = Dropout(0.3)(base_model)\n",
        "      output_layer = Dense(y_train.shape[1], activation='softmax', name='softmax')(base_model)\n",
        "\n",
        "      # 設定凍結與要進行訓練的網路層\n",
        "      net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "\n",
        "      for layer in net_final.layers[:layer_index]:\n",
        "          layer.trainable = False\n",
        "\n",
        "      return net_final\n",
        "  ###########################################################################################     \n",
        "  def iris_model(x_train, y_train, x_val, y_val, params):\n",
        "\n",
        "    with strategy.scope():\n",
        "      model = create_model(params)\n",
        "      precision=tf.keras.metrics.Precision(name='precision')\n",
        "      recall=tf.keras.metrics.Recall(name='recall')\n",
        "      accuracy=tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
        "      model.compile(optimizer=params['optimizer'],\n",
        "              loss=params['losses'],\n",
        "              metrics = [recall,precision,accuracy],\n",
        "             \n",
        "              )\n",
        "      print(model.summary())\n",
        "    callbacks_list=[\n",
        "      tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',mode='min', patience=10 ,restore_best_weights=True\n",
        "      )]\n",
        "      \n",
        "    out = model.fit(x1, y1,\n",
        "          batch_size=params['batch_size'],\n",
        "          epochs=params['epochs'],\n",
        "          validation_data=(x2,y2),\n",
        "          verbose=2,\n",
        "          callbacks=callbacks_list                \n",
        "            )\n",
        "    return out, model\n",
        "  ###########################################################################################\n",
        "  # with tf.keras.utils.CustomObjectScope():\n",
        "  scan_object = talos.Scan(x=x1,\n",
        "                y=y1,\n",
        "                x_val=x2,\n",
        "                y_val=y2,\n",
        "                model=iris_model,\n",
        "                params=p,\n",
        "                experiment_name='VGG16')\n",
        "    \n",
        "  return scan_object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFA8GIF5OocZ"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZrUjOGL1-v0"
      },
      "source": [
        "from talos import Deploy\n",
        "import datetime\n",
        "\n",
        "# 配合儲存模型，擷取時間\n",
        "def getTime():\n",
        "  dt0 = datetime.datetime.utcnow().replace(tzinfo=datetime.timezone.utc) # 展現獲取0時區時間\n",
        "  dt8 = dt0.astimezone(datetime.timezone(datetime.timedelta(hours=8)))  # 轉換時區到東八區\n",
        "  dt0 = datetime.datetime.strftime(dt0,'%m%d%H%M')\n",
        "  dt8 = datetime.datetime.strftime(dt8,'%m%d%H%M')\n",
        "  return dt8\n",
        "\n",
        "#  開始訓練\n",
        "scan_object=minimal(x_train,y_train,x_val,y_val)\n",
        "\n",
        "#  儲存模型\n",
        "file_name =\"VGG16_{}\".format(getTime())\n",
        "Deploy(scan_object,file_name ,metric='val_recall') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEdxNx4Nd661",
        "outputId": "c9775a9d-d9b3-4fc8-ce3b-28b2b76ee9e9"
      },
      "source": [
        "# /content/VGG16_04212053.zip\n",
        "Deploy(scan_object,'VGG16_04212053_1' ,metric='val_accuracy') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deploy package VGG16_04212053_1 have been saved.\n",
            "data is not 2d, dummy data written instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<talos.commands.deploy.Deploy at 0x7f6a391c3710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJui48vSus2R"
      },
      "source": [
        "# access the summary details\n",
        "print(scan_object.details)\n",
        "print(scan_object.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm4PjFfgUq7p",
        "outputId": "245e0726-f8e4-421f-a533-7a1b944a5248"
      },
      "source": [
        "scan_object"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<talos.scan.Scan.Scan at 0x7ff8e48f3b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "GAAtmMuzuxH-",
        "outputId": "586d51ef-a164-42d5-e7f9-74160751195e"
      },
      "source": [
        "best_model = scan_object.data[scan_object.data['val_recall']==scan_object.data['val_recall'].max()]\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_recall</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>activation</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>losses</th>\n",
              "      <th>node_1</th>\n",
              "      <th>node_2</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>regularizers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>04/21/21-120124</td>\n",
              "      <td>04/21/21-120228</td>\n",
              "      <td>63.788911</td>\n",
              "      <td>34</td>\n",
              "      <td>0.23628</td>\n",
              "      <td>0.9547</td>\n",
              "      <td>0.974035</td>\n",
              "      <td>0.9653</td>\n",
              "      <td>0.675733</td>\n",
              "      <td>0.8052</td>\n",
              "      <td>0.851703</td>\n",
              "      <td>0.8241</td>\n",
              "      <td>relu</td>\n",
              "      <td>3000</td>\n",
              "      <td>60</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>384</td>\n",
              "      <td>256</td>\n",
              "      <td>Adam</td>\n",
              "      <td>&lt;tensorflow.python.keras.regularizers.L2 objec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             start  ...                                       regularizers\n",
              "6  04/21/21-120124  ...  <tensorflow.python.keras.regularizers.L2 objec...\n",
              "\n",
              "[1 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZvRNQc_TTtW"
      },
      "source": [
        "precision=tf.keras.metrics.Precision(name='precision')\n",
        "recall=tf.keras.metrics.Recall(name='recall')\n",
        "accuracy=tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
        "best_model.compile(optimizer='Adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics = [recall,precision,accuracy],\n",
        "        )\n",
        "eval = best_model.evaluate( test_feature_vector, test_label_onehot )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wv0hJcDizY-"
      },
      "source": [
        "## 回復模型預測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLI0eXUfWP3N"
      },
      "source": [
        "\"\"\"\n",
        "此方法 CNN　會有問題\n",
        "\n",
        "ERROE\n",
        "Deploy package VGG16_04212053_1 have been saved.\n",
        "data is not 2d, dummy data written instead.\n",
        "<talos.commands.deploy.Deploy at 0x7f6a391c3710>\n",
        "\n",
        "# restore 回復模型預測\n",
        "# from talos import Restore\n",
        "restore = Restore('/content/drive/MyDrive/Colab Notebooks/VGG16_04212003.zip')\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIhj1is_hlby"
      },
      "source": [
        "\"\"\"\n",
        "CNN 適用此方法 恢復模型\n",
        "1. 找到被儲存的模型，Deploy的模型\n",
        "2. 使用以下方是讀取模型\n",
        "3. 路徑名稱到 _model 前\n",
        "\"\"\"\n",
        "import talos\n",
        "from talos.utils.load_model import load_model\n",
        "# /content/VGG16_04212003/VGG16_04212003_model.h5\n",
        "pre_model = load_model('/content/drive/MyDrive/Colab Notebooks/hw02/cifar10/VGG16_04212003/VGG16_04212003' + '_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP7ISzpo6Dox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db45115b-f189-43e9-ff8f-66c5d74ea1b3"
      },
      "source": [
        "pre_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,970,122\n",
            "Trainable params: 823,690\n",
            "Non-trainable params: 1,146,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCzQHXjVWrIF",
        "outputId": "a3967b4a-7bcf-4a61-9397-ca58cdbfa6bc"
      },
      "source": [
        "# restore 回復模型預測\n",
        "# restore.results\n",
        "precision=tf.keras.metrics.Precision(name='precision')\n",
        "recall=tf.keras.metrics.Recall(name='recall')\n",
        "accuracy=tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
        "\n",
        "# results_best_model = restore.results[restore.results['f1score']==restore.results['f1score'].max()]\n",
        "results_best_model = pre_model\n",
        "results_best_model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = [precision,recall,talos.utils.metrics.f1score,accuracy]\n",
        "                    )\n",
        "\n",
        "\n",
        "preds=results_best_model.evaluate(test_feature_vector,test_label_onehot)\n",
        "print('loss ： %.5f' % preds[0])\n",
        "print('Precision：%.5f' % preds[1])\n",
        "print('Recall：%.5f' % preds[2])\n",
        "print('f1score：%.5f' % preds[3])\n",
        "print('accuracy： %.5f' %preds[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 69s 216ms/step - loss: 0.6714 - precision: 0.8465 - recall: 0.7965 - f1score: 0.8201 - accuracy: 0.8164\n",
            "loss ： 0.6921972632408142\n",
            "Precision： 0.8410032987594604\n",
            "Recall： 0.7912999987602234\n",
            "f1score： 0.8149928450584412\n",
            "accuracy 0.8119999766349792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmWiD9sTJxxc",
        "outputId": "365b0539-e296-4a29-ceee-9fc448560813"
      },
      "source": [
        "results_best_model.history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FltsE1CIJWFy",
        "outputId": "e2a9ad5e-897c-40df-e60e-377c3a9d3df9"
      },
      "source": [
        "print('loss ： %.6f' % preds[0])\n",
        "print('Precision：%.6f' % preds[1])\n",
        "print('Recall：%.6f' % preds[2])\n",
        "print('f1score：%.6f' % preds[3])\n",
        "print('accuracy： %.6f' %preds[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss ： 0.692197\n",
            "Precision：0.841003\n",
            "Recall：0.791300\n",
            "f1score：0.814993\n",
            "accuracy： 0.812000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzSk1yKIaS_"
      },
      "source": [
        "\n",
        "313/313 [==============================] - 11s 32ms/step \n",
        "- loss: 0.6714 - precision: 0.8465 - recall: 0.7965 - f1score: 0.8201  accuracy: 0.8164\n",
        "\n",
        "---\n",
        "- loss ： 0.6921972036361694\n",
        "- Precision： 0.8410032987594604\n",
        "- Recall： 0.7912999987602234\n",
        "- f1score： 0.8149928450584412\n",
        "- accuracy 0.8119999766349792\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc5lHnjgyYdz"
      },
      "source": [
        "best_model1 = scan_object.data[scan_object.data['val_recall']==scan_object.data['val_recall'].max()]\n",
        "best_model1\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}